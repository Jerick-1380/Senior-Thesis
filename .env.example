# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Hugging Face Cache Configuration
HF_HOME=/data/user_data/your_username/hf_cache
TRANSFORMERS_CACHE=/data/user_data/your_username/hf_cache/transformers
HF_DATASETS_CACHE=/data/user_data/your_username/hf_cache/datasets
HF_METRICS_CACHE=/data/user_data/your_username/hf_cache/metrics

# vLLM Configuration
VLLM_API_KEY=token-abc123
VLLM_LOG_LEVEL=WARNING

# Model Server Configuration
LLM_API_BASE=http://localhost:8000/v1
MODEL_ID=meta-llama/Llama-3.1-8B-Instruct

# SLURM/Cluster Configuration (if using distributed computing)
SLURM_ARRAY_TASK_ID=0
SLURM_JOB_ID=12345

# Python Environment
PYTHONWARNINGS=ignore
LOGLEVEL=WARNING

# Optional: Temporary directory for large computations
TMPDIR=/data/user_data/your_username/tmp